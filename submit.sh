# python -m torch.distributed.launch --nproc_per_node=8 --use_env main.py --model deit_tiny_patch16_224 --layer_lr $1 --batch-size 64 --output_dir progressive --resume https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth --finetune_layer > train_$1.txt 2>&1 &
CUDA_VISIBLE_DEVICES=5,6,7,8,9 python -m torch.distributed.launch --nproc_per_node=5 --use_env main.py --model deit_tiny_patch16_224 --lr 1e-4 --epochs 200 --batch-size 128 --output_dir finetune_1e-4 --resume https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth
#python -m torch.distributed.launch --nproc_per_node=8 --use_env main.py --model deit_tiny_patch16_224 --lr 1e-5 --epochs 200 --batch-size 256 --output_dir finetune_200_3 --resume 'finetune_200_2/best_checkpoint.pth'
#python -m torch.distributed.launch --nproc_per_node=7 --use_env main.py --model deit_tiny_patch16_224 --lr 1e-4 --epochs 300 --batch-size 256 --output_dir finetune_1e-4_4 --resume 'finetune_1e-4_3/checkpoint.pth'
